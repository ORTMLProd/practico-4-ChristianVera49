{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b130f2-c013-47d0-8626-083f0f64cb61",
   "metadata": {},
   "source": [
    "# PrÃ¡ctico 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecef2a-e013-4d24-b967-acf1b4165d60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transform Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183974fa-de7a-467a-b3fb-ad5421071f52",
   "metadata": {},
   "source": [
    "**\"Transform pattern\"** en el contexto de Machine Learning se refiere a la tÃ©cnica de manipular y cambiar los datos de entrada antes de que sean utilizados por un modelo. \n",
    "\n",
    "Estos cambios pueden ayudar a mejorar el rendimiento del modelo y a hacer que el modelo sea mÃ¡s robusto ante variaciones en los datos de entrada.\n",
    "\n",
    "Las transformaciones se aplican tÃ­picamente durante la etapa de pre_procesamiento de los datos y pueden implicar muchas tÃ©cnicas diferentes, dependiendo del tipo de datos y del problema que se estÃ¡ tratando de resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b78b4d-8ec6-479d-930b-a9c9f985e641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.16.1) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.16.1) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.16.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.16.1) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow==2.16.1) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.16.1) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.43.0)\n",
      "Requirement already satisfied: rich in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a7eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 01:09:41.848968: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-17 01:09:41.850296: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 01:09:41.854798: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 01:09:42.009214: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 01:09:46.037867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99af7356-b9cd-4173-9960-cbb284d4e75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.2994 - loss: 2.2652 - val_accuracy: 0.1181 - val_loss: 2.9272\n",
      "Epoch 2/5\n",
      "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 586ms/step - accuracy: 0.5209 - loss: 1.3501 - val_accuracy: 0.2612 - val_loss: 2.2513\n",
      "Epoch 3/5\n",
      "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 572ms/step - accuracy: 0.6011 - loss: 1.1278 - val_accuracy: 0.6423 - val_loss: 1.0149\n",
      "Epoch 4/5\n",
      "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 574ms/step - accuracy: 0.6473 - loss: 1.0054 - val_accuracy: 0.6645 - val_loss: 0.9398\n",
      "Epoch 5/5\n",
      "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 585ms/step - accuracy: 0.6767 - loss: 0.9323 - val_accuracy: 0.7065 - val_loss: 0.8341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 47s, sys: 5.29 s, total: 16min 52s\n",
      "Wall time: 13min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Resizing, Rescaling\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar y normalizar el conjunto de datos \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convertir las etiquetas en one-hot\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "data_preprocessing = Sequential([\n",
    "    Resizing(32, 32),  # Redimensionar a 32x32\n",
    "    Rescaling(1./255)  # NormalizaciÃ³n adicional despuÃ©s del redimensionamiento\n",
    "])\n",
    "\n",
    "# Define tu modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "    data_preprocessing,\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),  # Ajustar a 3 canales de entrada\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compila y entrena el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Guarda el modelo\n",
    "model.save('transform_pattern_conv.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6482f-172d-45d3-b7bf-00043ed6629a",
   "metadata": {},
   "source": [
    "En este caso, las transformaciones de datos **(Resizing y Rescaling)** se definen como capas Keras y se agregan al inicio de tu modelo. \n",
    "\n",
    "Esto significa que estas transformaciones se aplicarÃ¡n automÃ¡ticamente a las imÃ¡genes a medida que pasen por el modelo, ya sea durante el entrenamiento o durante la inferencia. \n",
    "\n",
    "AdemÃ¡s, como las capas de preprocesamiento son parte del modelo, se guardarÃ¡n junto con el modelo cuando lo guardes con model.save(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d97697-1330-4217-8d4b-f3e1fef30dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21c689d-9fcf-4a17-a35e-bc74c9b7e6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment tracking\n",
    "### wandb: https://wandb.ai/site\n",
    "\n",
    "\n",
    "Primero, vamos a agregar experiment tracking utilizando wandb (Weights & Biases). Esto nos va a permitir monitorear los experimentos en tiempo real, guardar nuestros modelos , resultados, y podremos compartir experimentos con otros.\n",
    "\n",
    "[Wandb collab full explained notebook ](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb#scrollTo=jufPgkgqz2eF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86d672-e91f-4554-bcc3-9b8f02cd8ac7",
   "metadata": {},
   "source": [
    "### ğŸ‘Ÿ Run an experiment \n",
    "\n",
    "1.  **Start a new run** and pass in hyperparameters to track\n",
    "\n",
    "2.  **Log metrics** from training or evaluation\n",
    "\n",
    "3.  **Visualize results** in the dashboard\n",
    "\n",
    "4. **Generate alerts** in the dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c084e87b-bb3a-47f0-9332-b75771f2afb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb==0.17.0\n",
      "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb==0.17.0)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb==0.17.0)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb==0.17.0) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/codespace/.local/lib/python3.10/site-packages (from wandb==0.17.0) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb==0.17.0) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb==0.17.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.10/site-packages (from wandb==0.17.0) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb==0.17.0) (2.31.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb==0.17.0)\n",
      "  Downloading sentry_sdk-2.2.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb==0.17.0)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb==0.17.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb==0.17.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.17.0) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.17.0) (5.0.1)\n",
      "Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading sentry_sdk-2.2.0-py2.py3-none-any.whl (281 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, click, wandb\n",
      "Successfully installed click-8.1.7 docker-pycreds-0.4.0 sentry-sdk-2.2.0 setproctitle-1.3.3 wandb-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb==0.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cfcc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb version: 0.17.0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "print(\"wandb version:\", wandb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a294838a-6897-4ef3-b5c9-c9656a4b20f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchv-facu\u001b[0m (\u001b[33mchristianvera495\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/codespace/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "# Configura tu clave API directamente\n",
    "wandb.login(key='5f6ace794df4cab57a0ea72cf21c8c46ccd2beb7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb237a6a-14e4-46c0-9cd8-cd2a3c0f27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/practico-4-ChristianVera49/wandb/run-20240517_012601-c268evds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/christianvera495/ml-produccion-wandb/runs/c268evds' target=\"_blank\">hardy-cosmos-1</a></strong> to <a href='https://wandb.ai/christianvera495/ml-produccion-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/christianvera495/ml-produccion-wandb' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/christianvera495/ml-produccion-wandb/runs/c268evds' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb/runs/c268evds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.2517 - loss: 2.5847 - val_accuracy: 0.1643 - val_loss: 2.7888\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.4198 - loss: 1.6487 - val_accuracy: 0.1323 - val_loss: 3.1158\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.4928 - loss: 1.4053 - val_accuracy: 0.2061 - val_loss: 3.3668\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>â–â–†â–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_accuracy</td><td>â–„â–â–ˆ</td></tr><tr><td>val_loss</td><td>â–â–…â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.50706</td></tr><tr><td>loss</td><td>1.36905</td></tr><tr><td>val_accuracy</td><td>0.2061</td></tr><tr><td>val_loss</td><td>3.36678</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-cosmos-1</strong> at: <a href='https://wandb.ai/christianvera495/ml-produccion-wandb/runs/c268evds' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb/runs/c268evds</a><br/> View project at: <a href='https://wandb.ai/christianvera495/ml-produccion-wandb' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240517_012601-c268evds/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/practico-4-ChristianVera49/wandb/run-20240517_013317-li5b8tim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/christianvera495/ml-produccion-wandb/runs/li5b8tim' target=\"_blank\">vital-sky-2</a></strong> to <a href='https://wandb.ai/christianvera495/ml-produccion-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/christianvera495/ml-produccion-wandb' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/christianvera495/ml-produccion-wandb/runs/li5b8tim' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb/runs/li5b8tim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.4009 - loss: 1.7464 - val_accuracy: 0.1594 - val_loss: 2.7252\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.6224 - loss: 1.0704 - val_accuracy: 0.1186 - val_loss: 3.3521\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.6878 - loss: 0.8828 - val_accuracy: 0.1581 - val_loss: 3.1706\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>â–â–†â–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_accuracy</td><td>â–ˆâ–â–ˆ</td></tr><tr><td>val_loss</td><td>â–â–ˆâ–†</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.6947</td></tr><tr><td>loss</td><td>0.86819</td></tr><tr><td>val_accuracy</td><td>0.1581</td></tr><tr><td>val_loss</td><td>3.17064</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-sky-2</strong> at: <a href='https://wandb.ai/christianvera495/ml-produccion-wandb/runs/li5b8tim' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb/runs/li5b8tim</a><br/> View project at: <a href='https://wandb.ai/christianvera495/ml-produccion-wandb' target=\"_blank\">https://wandb.ai/christianvera495/ml-produccion-wandb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240517_013317-li5b8tim/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Resizing, Rescaling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "# Definir un callback personalizado para wandb\n",
    "class CustomWandbCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        wandb.log(logs, step=epoch)\n",
    "\n",
    "# Launch 2 experiments, trying different dropout rates\n",
    "for run in range(2):\n",
    "    \n",
    "    # Start a run, tracking hyperparameters\n",
    "    wandb.init(\n",
    "        project=\"ml-produccion-wandb\",\n",
    "        config={\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"dropout\": random.uniform(0.01, 0.80),\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"categorical_crossentropy\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"epoch\": 3,\n",
    "            \"batch_size\": 512,\n",
    "        },\n",
    "    )\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Cargar y normalizar el conjunto de datos \n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Convertir las etiquetas en one-hot\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    # Define el preprocesamiento de la imagen\n",
    "    data_preprocessing = Sequential([\n",
    "        Resizing(32, 32),  # Redimensionar a 32x32\n",
    "        Rescaling(1./255)  # NormalizaciÃ³n adicional despuÃ©s del redimensionamiento\n",
    "    ])\n",
    "\n",
    "    # Define tu modelo\n",
    "    model = tf.keras.models.Sequential([\n",
    "        data_preprocessing,  \n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(config.dropout),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(config.dropout),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compila y entrena el modelo\n",
    "    model.compile(optimizer=config.optimizer, loss=config.loss, metrics=[config.metric])\n",
    "\n",
    "    # Add CustomWandbCallback to log metrics\n",
    "    custom_wandb_callback = CustomWandbCallback()\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=config.batch_size, epochs=config.epoch, \n",
    "                        validation_data=(x_test, y_test), callbacks=[custom_wandb_callback])\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # Guardar el modelo\n",
    "    model.save(f'model_run_{run}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b83a6-2a7f-4566-b728-4d811d7cf5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ef8c1b0-5879-47a3-8318-8c57e403f4da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "##  W&B Alerts\n",
    "\n",
    "**[W&B Alerts](https://docs.wandb.ai/guides/track/alert)** allows you to send alerts, triggered from your Python code, to your Slack or email. There are 2 steps to follow the first time you'd like to send a Slack or email alert, triggered from your code:\n",
    "\n",
    "1) Turn on Alerts in your W&B [User Settings](https://wandb.ai/settings)\n",
    "\n",
    "2) Add `wandb.alert()` to your code:\n",
    "\n",
    "```python\n",
    "wandb.alert(\n",
    "    title=\"Low accuracy\", \n",
    "    text=f\"Accuracy is below the acceptable threshold\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c78284-a9aa-4479-aad3-3750d5b986f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/practico-4/wandb/run-20240515_220155-je97kal3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ortmlprod/alerts-intro/runs/je97kal3' target=\"_blank\">youthful-totem-1</a></strong> to <a href='https://wandb.ai/ortmlprod/alerts-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ortmlprod/alerts-intro' target=\"_blank\">https://wandb.ai/ortmlprod/alerts-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ortmlprod/alerts-intro/runs/je97kal3' target=\"_blank\">https://wandb.ai/ortmlprod/alerts-intro/runs/je97kal3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 1.122, 0.3\n",
      "Accuracy is: 0.607, 0.3\n",
      "Accuracy is: 0.588, 0.3\n",
      "Accuracy is: 1.249, 0.3\n",
      "Accuracy is: 1.182, 0.3\n",
      "Accuracy is: 0.842, 0.3\n",
      "Accuracy is: 0.991, 0.3\n",
      "Accuracy is: 1.105, 0.3\n",
      "Accuracy is: 1.336, 0.3\n",
      "Accuracy is: 1.602, 0.3\n",
      "Accuracy is: 1.5, 0.3\n",
      "Accuracy is: 1.071, 0.3\n",
      "Accuracy is: 0.928, 0.3\n",
      "Accuracy is: 1.786, 0.3\n",
      "Accuracy is: 0.751, 0.3\n",
      "Accuracy is: 0.912, 0.3\n",
      "Accuracy is: 0.959, 0.3\n",
      "Accuracy is: 0.251, 0.3\n",
      "Alert triggered\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>â–…â–ƒâ–ƒâ–†â–…â–„â–„â–…â–†â–‡â–‡â–…â–„â–ˆâ–ƒâ–„â–„â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.251</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-totem-1</strong> at: <a href='https://wandb.ai/ortmlprod/alerts-intro/runs/je97kal3' target=\"_blank\">https://wandb.ai/ortmlprod/alerts-intro/runs/je97kal3</a><br/> View project at: <a href='https://wandb.ai/ortmlprod/alerts-intro' target=\"_blank\">https://wandb.ai/ortmlprod/alerts-intro</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240515_220155-je97kal3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "# Start a wandb run\n",
    "wandb.init(project=\"alerts-intro\")\n",
    "\n",
    "# Simulating a model training loop\n",
    "acc_threshold = 0.3\n",
    "for training_step in range(1000):\n",
    "\n",
    "    # Generate a random number for accuracy\n",
    "    accuracy = round(random.random() + random.random(), 3)\n",
    "    print(f\"Accuracy is: {accuracy}, {acc_threshold}\")\n",
    "\n",
    "    # ğŸ Log accuracy to wandb\n",
    "    wandb.log({\"Accuracy\": accuracy})\n",
    "\n",
    "    # ğŸ”” If the accuracy is below the threshold, fire a W&B Alert and stop the run\n",
    "    if accuracy <= acc_threshold:\n",
    "        # ğŸ Send the wandb Alert\n",
    "        wandb.alert(\n",
    "            title=\"Low Accuracy\",\n",
    "            text=f\"Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}\",\n",
    "        )\n",
    "        print(\"Alert triggered\")\n",
    "        break\n",
    "\n",
    "# Mark the run as finished (useful in Jupyter notebooks)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9a234-68fe-402f-9cee-20a71337a05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc45011a-2fd8-4b5e-bb60-a8f772bbe99d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## H Tuning - wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7dfb660-ab0e-4af3-b391-54c937b1d277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cxwhl0r9\n",
      "Sweep URL: https://wandb.ai/ortmlprod/Htuning/sweeps/cxwhl0r9\n",
      "Iniciando el sweep...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep finalizado\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Cargar y normalizar el conjunto de datos\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# Usar solo una muestra del conjunto de datos de prueba\n",
    "x_test_small = x_test[:1]\n",
    "y_test_small = to_categorical(y_test[:1], 10)\n",
    "\n",
    "# Definir el callback personalizado para wandb\n",
    "class CustomWandbCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        wandb.log(logs, step=epoch)\n",
    "\n",
    "# Definir la configuraciÃ³n del sweep\n",
    "sweep_config = {\n",
    "    'method': 'grid',  # el mÃ©todo de bÃºsqueda de hiperparÃ¡metros\n",
    "    'metric': {\n",
    "        'name': 'accuracy',\n",
    "        'goal': 'maximize'  \n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.01]  # Un solo valor para minimizar el tiempo de ejecuciÃ³n\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64]  # Un solo valor para minimizar el tiempo de ejecuciÃ³n\n",
    "        },\n",
    "        'run_index': {\n",
    "            'values': [0, 1]  # Ãndices de los modelos a cargar\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Htuning\")\n",
    "\n",
    "# Definir la funciÃ³n de entrenamiento\n",
    "def train():\n",
    "    run = wandb.init()\n",
    "    config = run.config\n",
    "    \n",
    "    print(\"ConfiguraciÃ³n de la ejecuciÃ³n:\", config)\n",
    "    \n",
    "    # Mostrar archivos en el directorio actual\n",
    "    print(\"Archivos en el directorio actual:\", os.listdir('.'))\n",
    "    \n",
    "    # Cargar el modelo basado en el Ã­ndice del run\n",
    "    run_index = config.run_index\n",
    "    model_path = f\"model_run_{run_index}.h5\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Cargando el modelo desde {model_path}\")\n",
    "        model = load_model(model_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Archivo de modelo {model_path} no encontrado.\")\n",
    "    \n",
    "    print(f\"Evaluando el modelo {model_path}\")\n",
    "    \n",
    "    # Evaluar el modelo en los datos de prueba reducidos\n",
    "    loss, accuracy = model.evaluate(x_test_small, y_test_small, verbose=0)\n",
    "    \n",
    "    # Loguear los resultados en wandb\n",
    "    wandb.log({\"val_loss\": loss, \"val_accuracy\": accuracy})\n",
    "    print(f\"Modelo {model_path} - PÃ©rdida de validaciÃ³n: {loss}, PrecisiÃ³n de validaciÃ³n: {accuracy}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "    print(\"EjecuciÃ³n de Wandb finalizada\")\n",
    "\n",
    "# Ejecutar el agente\n",
    "print(\"Iniciando el sweep...\")\n",
    "wandb.agent(sweep_id, function=train)\n",
    "print(\"Sweep finalizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba221d39-c4b9-4f06-a2b0-d32a54277d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
